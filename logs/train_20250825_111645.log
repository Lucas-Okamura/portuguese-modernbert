2025-08-25 11:16:45 - INFO - Training with args: checkpoint_dir: checkpoints_v2
2025-08-25 11:16:45 - INFO - Training with args: resume_from: None
2025-08-25 11:16:45 - INFO - Training with args: model_name: answerdotai/ModernBERT-base
2025-08-25 11:16:45 - INFO - Training with args: tokenizer_name: ricardoz/BERTugues-base-portuguese-cased
2025-08-25 11:16:45 - INFO - Training with args: dataset_name: Itau-Unibanco/aroeira
2025-08-25 11:16:45 - INFO - Training with args: optimizer: adamw
2025-08-25 11:16:45 - INFO - Training with args: train_part: pt1
2025-08-25 11:16:45 - INFO - Training with args: rope_theta: 10000.0
2025-08-25 11:16:45 - INFO - Training with args: warmup_pct: 0.05
2025-08-25 11:16:45 - INFO - Training with args: decay_type: cosine
2025-08-25 11:16:45 - INFO - Training with args: decay_pct: 0.9
2025-08-25 11:16:45 - INFO - Training with args: min_lr: 1e-08
2025-08-25 11:16:45 - INFO - Training with args: epochs: 2
2025-08-25 11:16:45 - INFO - Training with args: total_samples: 34841241
2025-08-25 11:16:45 - INFO - Training with args: max_length: 1024
2025-08-25 11:16:45 - INFO - Training with args: batch_size: 16
2025-08-25 11:16:45 - INFO - Training with args: mlm_probability: 0.3
2025-08-25 11:16:45 - INFO - Training with args: mask_replace_prob: 1.0
2025-08-25 11:16:45 - INFO - Training with args: random_replace_prob: 0.0
2025-08-25 11:16:45 - INFO - Training with args: grad_accum: 32
2025-08-25 11:16:45 - INFO - Training with args: lr: 0.0005
2025-08-25 11:16:45 - INFO - Training with args: save_every: 100000
2025-08-25 11:16:45 - INFO - Training with args: log_every: 200
2025-08-25 11:16:45 - INFO - Training with args: log_dir: logs
2025-08-25 11:16:45 - INFO - Loading Config from answerdotai/ModernBERT-base with rope_theta=10000.0
2025-08-25 11:16:45 - INFO - Starting training from scratch of model answerdotai/ModernBERT-base.
2025-08-25 11:16:49 - INFO - Initializing Data Loader
2025-08-25 11:16:51 - INFO - Getting data from 0th sentence to 30000000th
2025-08-25 11:16:51 - INFO - Starting training from step 0
2025-08-25 11:16:52 - INFO - Initializing model with Accelerator
2025-08-25 11:16:52 - INFO - Initializing training
2025-08-25 11:16:52 - INFO - Dataset samples for training: 30000000
2025-08-25 11:16:52 - INFO - No. GPUs: 4
2025-08-25 11:16:52 - INFO - Batch Size per GPU: 16
2025-08-25 11:16:52 - INFO - Steps in dataset: 468750
2025-08-25 11:16:52 - INFO - Epochs: 2
2025-08-25 11:16:52 - INFO - Total Steps: 937500
