{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/portuguese-modernbert/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens and their IDs:\n",
      "pad_token: [PAD] - ID: 0\n",
      "cls_token: [CLS] - ID: 101\n",
      "sep_token: [SEP] - ID: 102\n",
      "mask_token: [MASK] - ID: 103\n",
      "unk_token: [UNK] - ID: 100\n",
      "\n",
      "All special tokens dictionary:\n",
      "{'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "\n",
    "print(\"Special tokens and their IDs:\")\n",
    "print(f\"pad_token: {tokenizer.pad_token} - ID: {tokenizer.pad_token_id}\")\n",
    "print(f\"cls_token: {tokenizer.cls_token} - ID: {tokenizer.cls_token_id}\")\n",
    "print(f\"sep_token: {tokenizer.sep_token} - ID: {tokenizer.sep_token_id}\")\n",
    "print(f\"mask_token: {tokenizer.mask_token} - ID: {tokenizer.mask_token_id}\")\n",
    "print(f\"unk_token: {tokenizer.unk_token} - ID: {tokenizer.unk_token_id}\")\n",
    "\n",
    "# Para ver todos os tokens especiais juntos:\n",
    "print(\"\\nAll special tokens dictionary:\")\n",
    "print(tokenizer.special_tokens_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens IDs from the model config:\n",
      "pad_token_id: 50283\n",
      "cls_token_id: 50281\n",
      "sep_token_id: 50282\n",
      "bos_token_id: 50281\n",
      "eos_token_id: 50282\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "\n",
    "print(\"Special tokens IDs from the model config:\")\n",
    "print(f\"pad_token_id: {model.config.pad_token_id}\")\n",
    "print(f\"cls_token_id: {model.config.cls_token_id}\")\n",
    "print(f\"sep_token_id: {model.config.sep_token_id}\")\n",
    "# print(f\"mask_token_id: {model.config.mask_token_id}\")\n",
    "print(f\"bos_token_id: {model.config.bos_token_id}\")  # início de sequência (se aplicável)\n",
    "print(f\"eos_token_id: {model.config.eos_token_id}\")  # fim de sequência (se aplicável)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_path = \"checkpoints/ckpt-5\"  # caminho local onde seu modelo foi salvo\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "pipe = pipeline(task=\"fill-mask\", model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29794"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_input_embeddings().num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/portuguese-modernbert/.venv/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:236: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9989151954650879,\n",
       "  'token': 103,\n",
       "  'token_str': '[MASK]',\n",
       "  'sequence': 'Hoje acordei. Meu cachorro morreu.'},\n",
       " {'score': 0.00027403116109780967,\n",
       "  'token': 221,\n",
       "  'token_str': 'para',\n",
       "  'sequence': 'Hoje acordei para. Meu cachorro morreu.'},\n",
       " {'score': 0.00024261799990199506,\n",
       "  'token': 223,\n",
       "  'token_str': 'ma',\n",
       "  'sequence': 'Hoje acordei ma. Meu cachorro morreu.'},\n",
       " {'score': 0.00011414106120355427,\n",
       "  'token': 19247,\n",
       "  'token_str': 'Magic',\n",
       "  'sequence': 'Hoje acordei Magic. Meu cachorro morreu.'},\n",
       " {'score': 7.527216075686738e-05,\n",
       "  'token': 110,\n",
       "  'token_str': '%',\n",
       "  'sequence': 'Hoje acordei %. Meu cachorro morreu.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Hoje acordei [MASK]. Meu cachorro morreu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.push_to_hub(\"LucasOkamura/test-modbert\")\n",
    "# tokenizer.push_to_hub(\"LucasOkamura/test-modbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
